# AI-VarDA: A Unified Variational Data Assimilation Framework for AI and Traditional Methods

This framework builds on our recent works, [FengWu-4DVar](https://openreview.net/forum?id=Y2WorV5ag6) and [VAE-Var](https://openreview.net/forum?id=utz99dx2RN), aiming to bridge traditional data assimilation techniques with modern deep generative modeling. **VAR-AI** is a modular and extensible Python-based framework that supports both classic variational methods (e.g., 3DVar, 4DVar, GEN_BE) and AI-driven approaches (e.g., VAE-Var, LoRA-EnVar). It offers a unified interface for integrating forecast models, background error representations, and observation operators â€” enabling flexible configuration, comparative experimentation, and reproducible research.



## ğŸŒŸ Key Features

- âœ… **Hybrid support** for AI-based and traditional DA algorithms
- ğŸ”Œ **Pluggable architecture**: swap decoders, models, and observation operators
- ğŸ“ˆ **Integrated support** for ensemble-based flow error propagation
- ğŸ§  **Learnable background error models** via VAE or GEN_BE-style approaches (See )
- ğŸ’¡ Designed for **weather forecasting**, but extensible to other geophysical applications



## ğŸ—‚ï¸ Project Structure Overview

```
assimilation_framework/
â”œâ”€â”€ assimilation_core/           # Core data assimilation logic
â”‚   â”œâ”€â”€ assimilation_models/     # All DA algorithm implementations (3DVar, 4DVar, VAE-Var, etc.)
â”‚   â”œâ”€â”€ bg_decoder_models/       # Control-to-physical variable decoders (linear, VAE, GEN_BE)
â”‚   â”œâ”€â”€ data_reader/             # Physical field and observation data loaders
â”‚   â”œâ”€â”€ flow_models/             # Forecast model for 4DVar flow dependendies
â”‚   â”œâ”€â”€ observation_operator/    # Observation operators (identity, interpolation, etc.)
â”‚   â”œâ”€â”€ ensemble_generator.py    # Ensemble background propagation
â”‚   â”œâ”€â”€ forecast_model.py        # Forecast model runner interface
â”‚   â”œâ”€â”€ init_states_constructor.py  # Initial ensemble state generator
â”‚   â”œâ”€â”€ evaluator.py             # Evaluation: error computation, diagnostics
â”‚   â””â”€â”€ runner.py                # Main assimilation process controller

â”œâ”€â”€ bgerr_learning/              # Static background error training modules
â”‚   â”œâ”€â”€ dataset/                 # ERA5-based datasets and normalization
â”‚   â”œâ”€â”€ learning_algorithms/     # GEN_BE and VAE-BE learners
â”‚   â”œâ”€â”€ utils/                   # Dataset builder utilities
â”‚   â””â”€â”€ runner.py                # Training entry point

â”œâ”€â”€ networks/                    # Deep learning architectures
â”‚   â”œâ”€â”€ bg_vae/                  # Background VAE model
â”‚   â”œâ”€â”€ fengwu_hr/               # FengWu high-resolution UNet + attention variants
â”‚   â”œâ”€â”€ fengwu_lr/               # Transformer-based FengWu low-resolution model

â”œâ”€â”€ utils/                       # Logging, metrics, helper functions
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ misc.py

scripts/                         # Python entry scripts
â”œâ”€â”€ run_assimilation_loop.py     # Online assimilation cycle
â””â”€â”€ learn_background_error.py    # Offline background error model training

bin/                             # Shell launch scripts (e.g., SLURM)
â”œâ”€â”€ run_assimilation_loop.sh
â”œâ”€â”€ run_genbe_learn_error.sh
â””â”€â”€ run_vaebe_learn_error.sh

config/                          # YAML-based experiment and model configs
â”œâ”€â”€ assimilation_loop/           # Configs for DA cycle
â””â”€â”€ bgerr_learning/              # Configs for GEN_BE and VAE training

checkpoints/                     # Pretrained models and intermediate outputs
â”œâ”€â”€ bgerr_models/                # Trained background error models (GEN_BE, VAE)
â”œâ”€â”€ forecast_models/             # FengWu model checkpoints
â”œâ”€â”€ flow_error/                  # Learned ensemble perturbation statistics
â””â”€â”€ observation_masks/           # Observation availability masks

experiments/                     # Output directory for experiment logs and results
â”œâ”€â”€ assimilation/
â””â”€â”€ learning_background/

README.md
```



## ğŸš€ Quick Start

This framework supports both **static background error learning** and **online data assimilation** via configurable YAML files.
 We provide three runnable shell scripts in `bin/` for common workflows:

### 1. Online Data Assimilation

Run the end-to-end data assimilation loop (e.g., 3DVar, VAE-4DVar, LoRA-EnVar):

```
bash bin/run_assimilation_loop.sh
```

This script launches a sequence of predefined experiments defined in:

- `config/assimilation_loop/exp_*.yaml`

The results and logs will be saved under:

```
experiments/assimilation/<experiment_prefix>/
```

------

### 2. Static Background Error Learning

#### GEN_BE-style learning:

```
bash bin/run_genbe_learn_error.sh
```

#### VAE-based learning:

```
bash bin/run_vaebe_learn_error.sh
```

Both use configurations in:

- `config/bgerr_learning/`

And save output to:

```
experiments/learning_background/<prefix>/
```

### 3. Customization

You can create or modify your own YAML config files to define:

- Assimilation algorithm (`gaussian_var`, `vae_var`, `lora_envar`, etc.)
- Forecast model and resolution
- Observation scenarios (random, gridded, interpolated)
- Background error representation (GEN_BE, VAE)
- Ensemble settings, time window size, training parameters, etc.

> ğŸ“ See `config/assimilation_loop/` and `config/bgerr_learning/` for examples.

Then, update the corresponding shell script or launch manually:

```
python scripts/run_assimilation_loop.py --config your_config.yaml --prefix your_run_name
```



## ğŸ“„ Related Publications

This framework implements and extends the following research works:

- **FengWu-4DVar**: Xiao et al., *FengWu-4DVar: Coupling the Data-Driven Weather Forecasting Model with 4D Variational Assimilation*. [[conference link](https://openreview.net/forum?id=Y2WorV5ag6)] [[arxiv link](https://arxiv.org/abs/2312.12455)]

  > Introduces a differentiable AI-forecast-driven 4DVar system capable of stable 1-year cycling 

- **VAE-Var**: Xiao et al., *VAE-Var: Variational-Autoencoder-Enhanced Variational Assimilation in Meteorology*. [[Conference link](https://openreview.net/forum?id=utz99dx2RN)]

  > Proposes a novel method to model background error distributions using deep generative models, enabling assimilation of off-grid observations.



## ğŸ“Œ Citation

If you use this framework or build upon FengWu-4DVar or VAE-Var, please cite:

```
@article{xiao2023fengwu,
  title={Fengwu-4dvar: Coupling the data-driven weather forecasting model with 4d variational assimilation},
  author={Xiao, Yi and Bai, Lei and Xue, Wei and Chen, Kang and Han, Tao and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2312.12455},
  year={2023}
}

@inproceedings{xiao2024towards,
  title={Towards a self-contained data-driven global weather forecasting framework},
  author={Xiao, Yi and Bai, Lei and Xue, Wei and Chen, Hao and Chen, Kun and Han, Tao and Ouyang, Wanli and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{xiao2025vae,
  title={VAE-Var: Variational autoencoder-enhanced variational methods for data assimilation in meteorology},
  author={Xiao, Yi and Jia, Qilong and Chen, Kun and Bai, Lei and Xue, Wei},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}
```



## âœ… TODO

We are actively developing and expanding the framework. Below is a roadmap of planned features:

### ğŸ”œ Short-Term Goals

-  **Support for real-world station observations**
   Integration of non-gridded, irregularly located surface station data into the assimilation pipeline (via configurable observation operators).

### ğŸ› ï¸ Long-Term Plans

-  **Implement additional traditional DA algorithms**
   Including hybrid EnKF-Var, weak-constraint 4DVar, and flow-dependent covariance models.
-  **Integrate with recent AI-based assimilation methods**
   Coupling with models like [DiffDA](https://arxiv.org/abs/2401.05932), [APPA](https://arxiv.org/abs/2504.18720), and other diffusion-based or neural inverse solvers.
-  **Assimilation of satellite and radar observations**
   Building generalized observation operators and preprocessing pipelines for satellite radiances and radar reflectivity.

*Feel free to open an issue or pull request if you'd like to contribute to any of these features!*

Maintainer: [Yi Xiao](mailto:xiaoyi200018@gmail.com)



